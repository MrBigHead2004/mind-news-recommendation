{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6942e9eb",
   "metadata": {},
   "source": [
    "# MIND News Recommendation System\n",
    "\n",
    "## Architecture Overview:\n",
    "1. **News Encoder:** BERT/RoBERTa + Attention Pooling (Title → Vector)\n",
    "2. **User Encoder:** Attention Pooling over history (History → User Vector)\n",
    "3. **Prediction:** Dot product similarity + Softmax\n",
    "4. **Training:** Negative Sampling with Cross-Entropy Loss\n",
    "\n",
    "## Pipeline:\n",
    "```\n",
    "User History → News Encoder → User Encoder → User Vector\n",
    "                                                  ↓\n",
    "Candidate News → News Encoder → Candidate Vectors → Dot Product → Click Probability\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbc67be",
   "metadata": {},
   "source": [
    "## Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e260463e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lenhathoang/miniconda3/envs/recsys/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet -r requirements.txt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from src import *\n",
    "\n",
    "# Set style for better plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085b8c94",
   "metadata": {},
   "source": [
    "## Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ede6b39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "CONFIGURATION\n",
      "==================================================\n",
      "NEWS_TRAIN_PATH      : /Users/lenhathoang/Developer/HUST Projects/mind-news-recommendation/MIND/MINDsmall_train/news.tsv\n",
      "NEWS_VAL_PATH        : /Users/lenhathoang/Developer/HUST Projects/mind-news-recommendation/MIND/MINDsmall_dev/news.tsv\n",
      "BEHAVIORS_TRAIN_PATH : /Users/lenhathoang/Developer/HUST Projects/mind-news-recommendation/MIND/MINDsmall_train/behaviors.tsv\n",
      "BEHAVIORS_VAL_PATH   : /Users/lenhathoang/Developer/HUST Projects/mind-news-recommendation/MIND/MINDsmall_dev/behaviors.tsv\n",
      "CHECKPOINT_PATH      : /Users/lenhathoang/Developer/HUST Projects/mind-news-recommendation/mind_news_rec.pth\n",
      "MODEL_NAME           : xlnet-base-cased\n",
      "EMBEDDING_DIM        : 768\n",
      "ATTENTION_QUERY_DIM  : 200\n",
      "MAX_TITLE_LEN        : 10\n",
      "MAX_HISTORY_LEN      : 20\n",
      "NEG_SAMPLES          : 4\n",
      "BATCH_SIZE           : 8\n",
      "EPOCHS               : 3\n",
      "LR                   : 4e-05\n",
      "DEVICE               : mps\n",
      "LOAD_CHECKPOINT      : True\n",
      "DEBUG_SUBSET_SIZE    : 100\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f687e071",
   "metadata": {},
   "source": [
    "## Download dataset from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "961a78e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8c0081",
   "metadata": {},
   "source": [
    "## News\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4e7555",
   "metadata": {},
   "source": [
    "### Load and Explore News Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b09d165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading News Articles from /Users/lenhathoang/Developer/HUST Projects/mind-news-recommendation/MIND/MINDsmall_train/news.tsv and /Users/lenhathoang/Developer/HUST Projects/mind-news-recommendation/MIND/MINDsmall_dev/news.tsv...\n",
      "  Training news: 51,282 articles\n",
      "  Validation news: 42,416 articles\n",
      "Loaded 65,238 unique news articles (combined)\n",
      "\n",
      "News Articles Samples:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N55528</td>\n",
       "      <td>The Brands Queen Elizabeth, Prince Charles, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N19639</td>\n",
       "      <td>50 Worst Habits For Belly Fat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N61837</td>\n",
       "      <td>The Cost of Trump's Aid Freeze in the Trenches...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N53526</td>\n",
       "      <td>I Was An NBA Wife. Here's How It Affected My M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N38324</td>\n",
       "      <td>How to Get Rid of Skin Tags, According to a De...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>N2073</td>\n",
       "      <td>Should NFL be able to fine players for critici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>N49186</td>\n",
       "      <td>It's been Orlando's hottest October ever so fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>N59295</td>\n",
       "      <td>Chile: Three die in supermarket fire amid prot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>N24510</td>\n",
       "      <td>Best PS5 games: top PlayStation 5 titles to lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>N39237</td>\n",
       "      <td>How to report weather-related closings, delays</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  news_id                                              title\n",
       "0  N55528  The Brands Queen Elizabeth, Prince Charles, an...\n",
       "1  N19639                      50 Worst Habits For Belly Fat\n",
       "2  N61837  The Cost of Trump's Aid Freeze in the Trenches...\n",
       "3  N53526  I Was An NBA Wife. Here's How It Affected My M...\n",
       "4  N38324  How to Get Rid of Skin Tags, According to a De...\n",
       "5   N2073  Should NFL be able to fine players for critici...\n",
       "6  N49186  It's been Orlando's hottest October ever so fa...\n",
       "7  N59295  Chile: Three die in supermarket fire amid prot...\n",
       "8  N24510  Best PS5 games: top PlayStation 5 titles to lo...\n",
       "9  N39237     How to report weather-related closings, delays"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df = load_news_data()\n",
    "\n",
    "print(f\"\\nNews Articles Samples:\")\n",
    "news_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0d3e49",
   "metadata": {},
   "source": [
    "### Tokenize News Articles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6b108a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing tokenizer: xlnet-base-cased...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing: 100%|██████████| 65238/65238 [00:07<00:00, 9184.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized 65,239 news articles (including <PAD>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Initializing tokenizer: {config['MODEL_NAME']}...\")\n",
    "news_features = tokenize_news(news_df)\n",
    "print(f\"Tokenized {len(news_features):,} news articles (including <PAD>)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22989647",
   "metadata": {},
   "source": [
    "## Create Training Samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acd56d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training samples...\n",
      "Strategy: 1 positive + 4 negative samples per training example\n",
      "Training dataset path: /Users/lenhathoang/Developer/HUST Projects/mind-news-recommendation/MIND/MINDsmall_train/behaviors.tsv\n",
      "Validation dataset path: /Users/lenhathoang/Developer/HUST Projects/mind-news-recommendation/MIND/MINDsmall_dev/behaviors.tsv\n",
      "DEBUG MODE: Using 100 train and 100 val behaviors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating train samples: 100%|██████████| 100/100 [00:00<00:00, 41947.23it/s]\n",
      "Creating val samples: 100%|██████████| 100/100 [00:00<00:00, 62396.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Created 137 training samples from /Users/lenhathoang/Developer/HUST Projects/mind-news-recommendation/MIND/MINDsmall_train/behaviors.tsv\n",
      "Created 100 validation samples from /Users/lenhathoang/Developer/HUST Projects/mind-news-recommendation/MIND/MINDsmall_dev/behaviors.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating training samples...\")\n",
    "print(f\"Strategy: 1 positive + {config['NEG_SAMPLES']} negative samples per training example\")\n",
    "\n",
    "train_behaviors_df, val_behaviors_df = load_behaviors_data()\n",
    "\n",
    "train_samples = create_behavior_samples(train_behaviors_df, 'train')\n",
    "val_samples = create_behavior_samples(val_behaviors_df, 'val')\n",
    "\n",
    "print(f\"\\nCreated {len(train_samples):,} training samples from {config['BEHAVIORS_TRAIN_PATH']}\")\n",
    "print(f\"Created {len(val_samples):,} validation samples from {config['BEHAVIORS_VAL_PATH']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120c7d00",
   "metadata": {},
   "source": [
    "## Create PyTorch Dataset and DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8348b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PyTorch datasets...\n",
      "Train dataset: 137 samples\n",
      "Validation dataset: 100 samples\n",
      "Train batches: 18\n",
      "Validation batches: 100\n"
     ]
    }
   ],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset for news recommendation\"\"\"\n",
    "    def __init__(self, samples, news_features, config):\n",
    "        self.samples = samples\n",
    "        self.news_features = news_features\n",
    "        self.config = config\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        \n",
    "        # Process history\n",
    "        history_ids = sample['history']\n",
    "        # Pad if shorter than max length\n",
    "        if len(history_ids) < self.config['MAX_HISTORY_LEN']:\n",
    "            history_ids = history_ids + ['<PAD>'] * (self.config['MAX_HISTORY_LEN'] - len(history_ids))\n",
    "        \n",
    "        # Stack history features\n",
    "        hist_input_ids = torch.cat([\n",
    "            self.news_features.get(nid, self.news_features['<PAD>'])['input_ids'] \n",
    "            for nid in history_ids\n",
    "        ])\n",
    "        hist_attn_mask = torch.cat([\n",
    "            self.news_features.get(nid, self.news_features['<PAD>'])['attention_mask'] \n",
    "            for nid in history_ids\n",
    "        ])\n",
    "        \n",
    "        # Process candidates\n",
    "        candidate_ids = sample['candidates']\n",
    "        cand_input_ids = torch.cat([\n",
    "            self.news_features.get(nid, self.news_features['<PAD>'])['input_ids'] \n",
    "            for nid in candidate_ids\n",
    "        ])\n",
    "        cand_attn_mask = torch.cat([\n",
    "            self.news_features.get(nid, self.news_features['<PAD>'])['attention_mask'] \n",
    "            for nid in candidate_ids\n",
    "        ])\n",
    "        \n",
    "        return {\n",
    "            'history_input_ids': hist_input_ids,\n",
    "            'history_attn_mask': hist_attn_mask,\n",
    "            'candidate_input_ids': cand_input_ids,\n",
    "            'candidate_attn_mask': cand_attn_mask,\n",
    "            'label': torch.tensor(sample['label'], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Create datasets\n",
    "print(\"Creating PyTorch datasets...\")\n",
    "train_dataset = NewsDataset(train_samples, news_features, config)\n",
    "val_dataset = NewsDataset(val_samples, news_features, config)\n",
    "\n",
    "print(f\"Train dataset: {len(train_dataset):,} samples\")\n",
    "print(f\"Validation dataset: {len(val_dataset):,} samples\")\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=config['BATCH_SIZE'], \n",
    "    shuffle=True,\n",
    "    num_workers=0  # Set to 0 to avoid multiprocessing issues\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=1,  # Variable number of candidates per sample\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87feb1e",
   "metadata": {},
   "source": [
    "## Initialize Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57f119c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'XLNetModel' object has no attribute 'encoder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Unfreeze only the last N transformer layers\u001b[39;00m\n\u001b[1;32m      7\u001b[0m num_layers_to_unfreeze \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m  \u001b[38;5;66;03m# Adjust this (try 1-3)\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnews_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[38;5;241m.\u001b[39mlayer[\u001b[38;5;241m-\u001b[39mnum_layers_to_unfreeze:]:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mparameters():\n\u001b[1;32m     10\u001b[0m         param\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/recsys/lib/python3.9/site-packages/torch/nn/modules/module.py:1962\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1960\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1961\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1962\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1963\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1964\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'XLNetModel' object has no attribute 'encoder'"
     ]
    }
   ],
   "source": [
    "model = NewsRecommender(config).to(config['DEVICE'])\n",
    "\n",
    "# for param in model.news_encoder.embedding.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# # Unfreeze only the last N transformer layers\n",
    "# num_layers_to_unfreeze = 2  # Adjust this (try 1-3)\n",
    "# for layer in model.news_encoder.embedding.encoder.layer[-num_layers_to_unfreeze:]:\n",
    "#     for param in layer.parameters():\n",
    "#         param.requires_grad = True\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config['LR'])\n",
    "# optimizer = torch.optim.AdamW([\n",
    "#     # Pretrained RoBERTa - lower learning rate\n",
    "#     {'params': model.news_encoder.embedding.parameters(), 'lr': 1e-5},\n",
    "#     # Custom attention layers - higher learning rate\n",
    "#     {'params': model.news_encoder.attention_pooling.parameters(), 'lr': 1e-4},\n",
    "#     {'params': model.user_attention.parameters(), 'lr': 1e-4}\n",
    "# ], weight_decay=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(f\"Model initialized on {config['DEVICE']}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fdfc4d",
   "metadata": {},
   "source": [
    "## Train the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e47a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, train_loader, val_loader, optimizer, criterion, config['DEVICE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818f57de",
   "metadata": {},
   "source": [
    "## Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fdb6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the checkpoint to get training history\n",
    "checkpoint = torch.load('mind_news_rec.pth', map_location=config['DEVICE'])\n",
    "history = checkpoint['history']\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Training Progress', fontsize=16)\n",
    "\n",
    "# Plot training loss\n",
    "axes[0, 0].plot(history['epoch'], history['train_loss'], 'b-', marker='o')\n",
    "axes[0, 0].set_title('Training Loss')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "# Plot validation AUC\n",
    "axes[0, 1].plot(history['epoch'], history['val_auc'], 'r-', marker='o')\n",
    "axes[0, 1].set_title('Validation AUC')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('AUC')\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "# Plot validation MRR\n",
    "axes[1, 0].plot(history['epoch'], history['val_mrr'], 'g-', marker='o')\n",
    "axes[1, 0].set_title('Validation MRR')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('MRR')\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "# Plot validation NDCG@5 and NDCG@10\n",
    "axes[1, 1].plot(history['epoch'], history['val_ndcg@5'], 'purple', marker='o', label='NDCG@5')\n",
    "axes[1, 1].plot(history['epoch'], history['val_ndcg@10'], 'orange', marker='s', label='NDCG@10')\n",
    "axes[1, 1].set_title('Validation NDCG')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('NDCG')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print final metrics\n",
    "print(\"\\nFinal Training Results:\")\n",
    "print(f\"Final Training Loss: {history['train_loss'][-1]:.4f}\")\n",
    "print(f\"Best Validation AUC: {max(history['val_auc']):.4f}\")\n",
    "print(f\"Best Validation MRR: {max(history['val_mrr']):.4f}\")\n",
    "print(f\"Best Validation NDCG@5: {max(history['val_ndcg@5']):.4f}\")\n",
    "print(f\"Best Validation NDCG@10: {max(history['val_ndcg@10']):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
